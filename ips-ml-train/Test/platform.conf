#######################################
# LOCATIONS
#######################################
IPS_PATH = $IPS_ROOT


#########################################
# ips-wrappers path.
IPS_WRAPPERS_ROOT = /global/homes/m/markcian/ips-wrappers

# ips-massive-serial-runner Locations
# Path to the ips-massive-serial-runner component scripts.
IPS_MASSIVE_SERIAL_RUNNER_COMP_PATH = $IPS_WRAPPERS_ROOT/ips-massive-serial-runner

# Install path for the system code root.
SYSTEM_CODE_INSTALL_ROOT = /global/homes/m/markcian/systemcode

# Install path and name for the random input space sampling script.
SAMPLE_INSTALL_PATH = $SYSTEM_CODE_INSTALL_ROOT/kernel/scan/fastran
SAMPLE_INSTALL_NAME = sample.py

# Install path and name for the name database script.
MAKE_DATABASE_INSTALL_PATH = $SYSTEM_CODE_INSTALL_ROOT/kernel/data/fastran
MAKE_DATABASE_INSTALL_NAME = makedb.py

# Install path and name for the to json script.
TO_JSON_INSTALL_PATH = $SYSTEM_CODE_INSTALL_ROOT/data/utilities
TO_JSON_INSTALL_NAME = tojson.py

# Install path and name for the massive serial runner.
MASSIVE_SERIAL_INSTALL_PATH = $FASTRAN_ROOT/bin
MASSIVE_SERIAL_INSTALL_NAME = ips_massive_serial.py

# ips-ml-train Locations
#  Path to the ips-ml-train component scripts.
IPS_ML_TRAIN_COMP_PATH = $IPS_WRAPPERS_ROOT/ips-ml-train

#  ML Train Install Path and name. Install path is the path to the directory
#  where ml_train_exe.py is installed. Install name is the name of the
#  ml_train_exe.py executable.

ML_TRAIN_INSTALL_PATH = $SYSTEM_CODE_INSTALL_ROOT/ml
ML_TRAIN_INSTALL_NAME = model_train.py

# Python binary.
PYTHON = python

#######################################
# Parallel environment
#######################################
MPIRUN = srun
NODE_DETECTION = slurm_env
CORES_PER_NODE = 32
SOCKETS_PER_NODE = 2
NODE_ALLOCATION_MODE = EXCLUSIVE

#######################################
# Provenance
#######################################
HOST = cori
USER = markcian
HOME = /global/homes/m/$USER
#SCRATCH =

USER_W3_DIR =

###
## DOCUMENTATION
#
#######################################
# NODE_ALLOCATION_MODE
#
# MUST ADHERE TO THE PLATFORM'S CAPABILITIES
#   * EXCLUSIVE : only one task per node
#   * SHARED : multiple tasks may share a node
# For single node jobs, this can be overridden allowing multiple
# tasks per node.
#
#######################################
# NODE_DETECTION =resource detection method
#
# OPTIONS = checkjob | qstat | pbs_env | slurm_env
#
#######################################
